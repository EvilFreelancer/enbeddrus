{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Импортируем необходимые библиотеки\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "base_model_name_or_path = \"Snowflake/snowflake-arctic-embed-xs\"\n",
    "tuned_model_name_or_path = \"./output/model_domain-en-ru-2024-05-18_14-12-55\"\n",
    "dataset_name = \"evilfreelancer/php-ru-en\"\n",
    "\n",
    "# Загружаем модели SentencePiece\n",
    "base_model = SentenceTransformer(base_model_name_or_path)\n",
    "tuned_model = SentenceTransformer(tuned_model_name_or_path)\n",
    "\n",
    "# Загрузка датасета с HuggingFace\n",
    "dataset = load_dataset(dataset_name)\n",
    "\n",
    "# Пример использования: предположим, что датасет содержит поля 'english' и 'russian' с соответствующими фразами\n",
    "english_phrases = dataset['eval']['English']\n",
    "russian_phrases = dataset['eval']['Russian']\n",
    "\n",
    "# Получение эмбеддингов для первых 50 пар фраз\n",
    "n_samples = 100\n",
    "base_embeddings = []\n",
    "fine_tuned_embeddings = []\n",
    "\n",
    "for i in range(n_samples):\n",
    "    eng_phrase = english_phrases[i]\n",
    "    rus_phrase = russian_phrases[i]\n",
    "\n",
    "    # Extract embeddings for base model\n",
    "    base_eng_embedding = base_model.encode(eng_phrase)\n",
    "    base_rus_embedding = base_model.encode(rus_phrase)\n",
    "    base_embeddings.append(base_eng_embedding)\n",
    "    base_embeddings.append(base_rus_embedding)\n",
    "\n",
    "    # Extract embeddings for tuned model\n",
    "    fine_tuned_eng_embedding = tuned_model.encode(eng_phrase)\n",
    "    fine_tuned_rus_embedding = tuned_model.encode(rus_phrase)\n",
    "    fine_tuned_embeddings.append(fine_tuned_eng_embedding)\n",
    "    fine_tuned_embeddings.append(fine_tuned_rus_embedding)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Функция для расчета косинусного сходства\n",
    "def cosine_similarity(emb1, emb2):\n",
    "    dot_product = np.dot(emb1, emb2)\n",
    "    norm_emb1 = np.linalg.norm(emb1)\n",
    "    norm_emb2 = np.linalg.norm(emb2)\n",
    "    return dot_product / (norm_emb1 * norm_emb2)\n",
    "\n",
    "\n",
    "# Расчет косинусного сходства для базовой и дообученной моделей\n",
    "base_similarities = []\n",
    "fine_tuned_similarities = []\n",
    "\n",
    "for i in range(0, len(base_embeddings), 2):\n",
    "    base_similarity = cosine_similarity(base_embeddings[i], base_embeddings[i + 1])\n",
    "    fine_tuned_similarity = cosine_similarity(fine_tuned_embeddings[i], fine_tuned_embeddings[i + 1])\n",
    "\n",
    "    base_similarities.append(base_similarity)\n",
    "    fine_tuned_similarities.append(fine_tuned_similarity)"
   ],
   "id": "43c6e886cb4608b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Визуализация различий между базовой моделью и дообученной моделью\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.plot(base_similarities, label='Base Model Similarities', marker='o')\n",
    "plt.plot(fine_tuned_similarities, label='Fine-Tuned Model Similarities', marker='o')\n",
    "\n",
    "plt.title('Cosine Similarities between English and Russian Phrases')\n",
    "plt.xlabel('Phrase Pair Index')\n",
    "plt.ylabel('Cosine Similarity')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# TSNE визуализация эмбеддингов\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "\n",
    "base_embeddings_2d = tsne.fit_transform(np.array(base_embeddings))\n",
    "fine_tuned_embeddings_2d = tsne.fit_transform(np.array(fine_tuned_embeddings))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.scatter(base_embeddings_2d[:, 0], base_embeddings_2d[:, 1], label='Base Model Embeddings', alpha=0.5)\n",
    "plt.scatter(fine_tuned_embeddings_2d[:, 0], fine_tuned_embeddings_2d[:, 1], label='Fine-Tuned Model Embeddings',\n",
    "            alpha=0.5)\n",
    "\n",
    "plt.title('TSNE Visualization of Embeddings')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "6a2ee4a390f2369b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
