{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from datasets import load_dataset\n",
    "\n",
    "base_model_name_or_path = \"bert-base-multilingual-uncased\"\n",
    "# base_model_name_or_path = \"Snowflake/snowflake-arctic-embed-m\"\n",
    "# base_model_name_or_path = \"mixedbread-ai/mxbai-embed-large-v1\"\n",
    "tuned_model_name_or_path = \"output/enbeddrus-en-ru-2024-05-19_18-46-49\" # domain\n",
    "# tuned_model_name_or_path = \"output/enbeddrus-en-ru-2024-05-20_11-30-48\" # parallel\n",
    "\n",
    "dataset_name = \"evilfreelancer/opus-php-en-ru-cleaned\"\n",
    "\n",
    "# Load models\n",
    "base_model = SentenceTransformer(base_model_name_or_path)\n",
    "tuned_model = SentenceTransformer(tuned_model_name_or_path)\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(dataset_name)\n",
    "\n",
    "# Split dataset\n",
    "english_phrases = dataset['eval']['English']\n",
    "russian_phrases = dataset['eval']['Russian']\n",
    "\n",
    "# Extract embeddings from base model\n",
    "base_eng_embedding = base_model.encode(english_phrases)\n",
    "base_rus_embedding = base_model.encode(russian_phrases)\n",
    "\n",
    "# Extract embeddings from tuned model\n",
    "tuned_eng_embedding = tuned_model.encode(english_phrases)\n",
    "tuned_rus_embedding = tuned_model.encode(russian_phrases)"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Функция для расчета косинусного сходства\n",
    "def cosine_similarity(emb1, emb2):\n",
    "    dot_product = np.dot(emb1, emb2)\n",
    "    norm_emb1 = np.linalg.norm(emb1)\n",
    "    norm_emb2 = np.linalg.norm(emb2)\n",
    "    return dot_product / (norm_emb1 * norm_emb2)\n",
    "\n",
    "\n",
    "# Расчет косинусного сходства для базовой и дообученной моделей\n",
    "base_similarities = []\n",
    "tuned_similarities = []\n",
    "\n",
    "for i in range(len(base_eng_embedding)):\n",
    "    base_similarity = cosine_similarity(base_eng_embedding[i], base_rus_embedding[i])\n",
    "    tuned_similarity = cosine_similarity(tuned_eng_embedding[i], tuned_rus_embedding[i])\n",
    "\n",
    "    base_similarities.append(base_similarity)\n",
    "    tuned_similarities.append(tuned_similarity)"
   ],
   "id": "43c6e886cb4608b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Set up the figure and axes\n",
    "fig, axs = plt.subplots(1, 3, figsize=(24, 6))\n",
    "\n",
    "# Plot the cosine similarities\n",
    "axs[2].plot(base_similarities, label='Base Model Similarities', marker='o')\n",
    "axs[2].plot(tuned_similarities, label='Tuned Model Similarities', marker='o')\n",
    "axs[2].set_title('Cosine Similarities between English and Russian Phrases')\n",
    "axs[2].set_xlabel('Phrase Pair Index')\n",
    "axs[2].set_ylabel('Cosine Similarity')\n",
    "axs[2].legend()\n",
    "axs[2].grid(True)\n",
    "\n",
    "# TSNE visualization of embeddings\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "\n",
    "base_embeddings_2d = tsne.fit_transform(np.concatenate((base_eng_embedding, base_rus_embedding)))\n",
    "tuned_embeddings_2d = tsne.fit_transform(np.concatenate((tuned_eng_embedding, tuned_rus_embedding)))\n",
    "\n",
    "# Scatter plot of embeddings\n",
    "axs[1].scatter(\n",
    "    tuned_embeddings_2d[:len(tuned_eng_embedding), 0],\n",
    "    tuned_embeddings_2d[:len(tuned_eng_embedding), 1],\n",
    "    label='Tuned Model English Embeddings', alpha=0.5\n",
    ")\n",
    "axs[1].scatter(\n",
    "    tuned_embeddings_2d[len(tuned_rus_embedding):, 0],\n",
    "    tuned_embeddings_2d[len(tuned_rus_embedding):, 1],\n",
    "    label='Tuned Model Russian Embeddings', alpha=0.5\n",
    ")\n",
    "axs[1].set_title('TSNE Visualization of Embeddings (tuned)')\n",
    "axs[1].legend()\n",
    "\n",
    "axs[0].scatter(\n",
    "    base_embeddings_2d[:len(base_eng_embedding), 0],\n",
    "    base_embeddings_2d[:len(base_eng_embedding), 1],\n",
    "    label='Base Model English Embeddings', alpha=0.5\n",
    ")\n",
    "axs[0].scatter(\n",
    "    base_embeddings_2d[len(base_rus_embedding):, 0],\n",
    "    base_embeddings_2d[len(base_rus_embedding):, 1],\n",
    "    label='Base Model Russian Embeddings', alpha=0.5\n",
    ")\n",
    "axs[0].set_title('TSNE Visualization of Embeddings (base)')\n",
    "axs[0].legend()\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ],
   "id": "6a2ee4a390f2369b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
